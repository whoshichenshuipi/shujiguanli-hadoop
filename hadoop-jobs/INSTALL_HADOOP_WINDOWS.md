# Windows ä¸Šå®‰è£…é…ç½® Hadoop 3.3.6 æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ åœ¨ Windows ä¸Šå®‰è£…å’Œé…ç½® Hadoop 3.3.6 ä¼ªåˆ†å¸ƒå¼ç¯å¢ƒã€‚

## âš ï¸ é‡è¦æç¤º

**Hadoop åœ¨ Windows ä¸Šçš„è¿è¡Œå¹¶ä¸æ˜¯å®˜æ–¹æ¨èçš„æ–¹å¼**ã€‚å¦‚æœå¯èƒ½ï¼Œå»ºè®®ä½¿ç”¨ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆï¼š

### æ¨èæ›¿ä»£æ–¹æ¡ˆ

1. **WSL2 (Windows Subsystem for Linux)** â­ æ¨è
   - åœ¨ Windows ä¸Šè¿è¡Œå®Œæ•´çš„ Linux ç¯å¢ƒ
   - Hadoop è¿è¡Œæ›´ç¨³å®š
   - é…ç½®æ›´ç®€å•

2. **Docker Desktop**
   - ä½¿ç”¨ Hadoop Docker é•œåƒ
   - ä¸€é”®å¯åŠ¨ï¼Œæ— éœ€å¤æ‚é…ç½®

3. **è™šæ‹Ÿæœº (VirtualBox/VMware)**
   - å®‰è£… Ubuntu/CentOS
   - å®Œæ•´çš„ Linux ç¯å¢ƒ

4. **äº‘æœåŠ¡**
   - é˜¿é‡Œäº‘ MaxCompute
   - AWS EMR
   - Azure HDInsight

## ğŸ”§ æ–¹æ¡ˆ 1: ä½¿ç”¨ WSL2 (æ¨è)

### æ­¥éª¤ 1: å®‰è£… WSL2

```powershell
# ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ PowerShell

# å¯ç”¨ WSL
wsl --install

# é‡å¯ç”µè„‘åï¼Œå®‰è£… Ubuntu
wsl --install -d Ubuntu-22.04

# è¿›å…¥ WSL
wsl
```

### æ­¥éª¤ 2: åœ¨ WSL ä¸­å®‰è£… Hadoop

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£… Java
sudo apt install openjdk-8-jdk -y

# éªŒè¯ Java å®‰è£…
java -version

# ä¸‹è½½ Hadoop
cd ~
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz

# è§£å‹
tar -xzf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /usr/local/hadoop

# é…ç½®ç¯å¢ƒå˜é‡
echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' >> ~/.bashrc
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
source ~/.bashrc

# éªŒè¯å®‰è£…
hadoop version
```

### æ­¥éª¤ 3: é…ç½® Hadoop ä¼ªåˆ†å¸ƒå¼

```bash
# é…ç½® hadoop-env.sh
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# é…ç½® core-site.xml
cat > $HADOOP_HOME/etc/hadoop/core-site.xml << 'EOF'
<?xml version="1.0"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
EOF

# é…ç½® hdfs-site.xml
cat > $HADOOP_HOME/etc/hadoop/hdfs-site.xml << 'EOF'
<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///home/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///home/hadoop/data/datanode</value>
    </property>
</configuration>
EOF

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p ~/data/namenode
mkdir -p ~/data/datanode

# é…ç½® SSH å…å¯†ç™»å½•
sudo apt install openssh-server -y
sudo service ssh start
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys

# æ ¼å¼åŒ– NameNode
hdfs namenode -format

# å¯åŠ¨ Hadoop
start-dfs.sh

# éªŒè¯
hdfs dfs -ls /
```

### æ­¥éª¤ 4: åœ¨ WSL ä¸­è¿è¡Œ MapReduce ä»»åŠ¡

```bash
# åˆ›å»º HDFS ç›®å½•
hdfs dfs -mkdir -p /library/logs
hdfs dfs -mkdir -p /library/output

# ä» Windows è®¿é—® WSL æ–‡ä»¶
# Windows è·¯å¾„: \\wsl$\Ubuntu-22.04\home\<username>

# å¤åˆ¶ JAR æ–‡ä»¶åˆ° WSL
# åœ¨ Windows PowerShell ä¸­:
# cp b:\jproject\tushu-hadoop\hadoop-jobs\target\*.jar \\wsl$\Ubuntu-22.04\home\<username>\

# åœ¨ WSL ä¸­è¿è¡Œä»»åŠ¡
hadoop jar library-hadoop-jobs-0.0.1-SNAPSHOT.jar \
  com.example.library.mr.HotBookJob \
  /library/logs \
  /library/output/hot-books
```

## ğŸ³ æ–¹æ¡ˆ 2: ä½¿ç”¨ Docker (ç®€å•å¿«é€Ÿ)

### æ­¥éª¤ 1: å®‰è£… Docker Desktop

1. ä¸‹è½½å¹¶å®‰è£… [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/)
2. å¯åŠ¨ Docker Desktop

### æ­¥éª¤ 2: è¿è¡Œ Hadoop å®¹å™¨

```powershell
# æ‹‰å– Hadoop é•œåƒ
docker pull apache/hadoop:3.3.6

# è¿è¡Œ Hadoop å®¹å™¨
docker run -d --name hadoop-dev `
  -p 9870:9870 `
  -p 8088:8088 `
  -p 9000:9000 `
  -v b:\jproject\tushu-hadoop\hadoop-jobs:/opt/hadoop-jobs `
  apache/hadoop:3.3.6

# è¿›å…¥å®¹å™¨
docker exec -it hadoop-dev bash

# åœ¨å®¹å™¨å†…è¿è¡Œ MapReduce ä»»åŠ¡
cd /opt/hadoop-jobs
hadoop jar target/library-hadoop-jobs-0.0.1-SNAPSHOT.jar \
  com.example.library.mr.HotBookJob \
  /library/logs \
  /library/output/hot-books
```

## ğŸ’» æ–¹æ¡ˆ 3: åŸç”Ÿ Windows å®‰è£… (ä¸æ¨è)

å¦‚æœä½ åšæŒåœ¨åŸç”Ÿ Windows ä¸Šå®‰è£… Hadoopï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

### å‰ç½®è¦æ±‚

1. **Java JDK 8**
   ```powershell
   # æ£€æŸ¥ Java ç‰ˆæœ¬
   java -version
   
   # å¦‚æœæ²¡æœ‰ï¼Œä¸‹è½½å®‰è£… JDK 8
   # https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html
   ```

2. **é…ç½® JAVA_HOME**
   ```powershell
   # è®¾ç½®ç¯å¢ƒå˜é‡
   [System.Environment]::SetEnvironmentVariable('JAVA_HOME', 'C:\Program Files\Java\jdk1.8.0_xxx', 'Machine')
   ```

### å®‰è£…æ­¥éª¤

#### 1. ä¸‹è½½ Hadoop

```powershell
# åˆ›å»ºå®‰è£…ç›®å½•
New-Item -Path "C:\hadoop" -ItemType Directory -Force

# ä¸‹è½½ Hadoop 3.3.6
# è®¿é—®: https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/
# ä¸‹è½½: hadoop-3.3.6.tar.gz

# è§£å‹åˆ° C:\hadoop
# ä½¿ç”¨ 7-Zip æˆ– WinRAR è§£å‹
```

#### 2. ä¸‹è½½ Windows è¡¥ä¸æ–‡ä»¶

```powershell
# Hadoop éœ€è¦é¢å¤–çš„ Windows äºŒè¿›åˆ¶æ–‡ä»¶
# ä¸‹è½½ winutils.exe å’Œ hadoop.dll

# è®¿é—®: https://github.com/cdarlint/winutils
# ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„æ–‡ä»¶åˆ° C:\hadoop\hadoop-3.3.6\bin\
```

#### 3. é…ç½®ç¯å¢ƒå˜é‡

```powershell
# è®¾ç½® HADOOP_HOME
[System.Environment]::SetEnvironmentVariable('HADOOP_HOME', 'C:\hadoop\hadoop-3.3.6', 'Machine')

# æ·»åŠ åˆ° PATH
$path = [System.Environment]::GetEnvironmentVariable('Path', 'Machine')
$newPath = $path + ';C:\hadoop\hadoop-3.3.6\bin;C:\hadoop\hadoop-3.3.6\sbin'
[System.Environment]::SetEnvironmentVariable('Path', $newPath, 'Machine')

# é‡å¯ PowerShell ä½¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ
```

#### 4. é…ç½® Hadoop

ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼ˆä½äº `C:\hadoop\hadoop-3.3.6\etc\hadoop\`ï¼‰ï¼š

**core-site.xml**:
```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

**hdfs-site.xml**:
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///C:/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///C:/hadoop/data/datanode</value>
    </property>
</configuration>
```

**hadoop-env.cmd**:
```cmd
set JAVA_HOME=C:\Program Files\Java\jdk1.8.0_xxx
```

#### 5. æ ¼å¼åŒ–å¹¶å¯åŠ¨

```powershell
# åˆ›å»ºæ•°æ®ç›®å½•
New-Item -Path "C:\hadoop\data\namenode" -ItemType Directory -Force
New-Item -Path "C:\hadoop\data\datanode" -ItemType Directory -Force

# æ ¼å¼åŒ– NameNode
hdfs namenode -format

# å¯åŠ¨ HDFS (éœ€è¦ç®¡ç†å‘˜æƒé™)
start-dfs.cmd

# éªŒè¯
hdfs dfs -ls /
```

## ğŸ¯ æ¨èæ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | éš¾åº¦ | ç¨³å®šæ€§ | æ€§èƒ½ | æ¨èåº¦ |
|------|------|--------|------|--------|
| WSL2 | â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| Docker | â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| åŸç”Ÿ Windows | â­â­â­â­â­ | â­â­ | â­â­ | â­ |
| äº‘æœåŠ¡ | â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |

## ğŸ“ æˆ‘çš„å»ºè®®

**å¯¹äºä½ çš„é¡¹ç›®ï¼Œæˆ‘å¼ºçƒˆæ¨èä½¿ç”¨ WSL2 æ–¹æ¡ˆ**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. âœ… é…ç½®ç®€å•ï¼Œä¸€æ¬¡æ€§å®Œæˆ
2. âœ… ç¨³å®šæ€§é«˜ï¼Œå®Œå…¨å…¼å®¹ Hadoop
3. âœ… å¯ä»¥ç›´æ¥è®¿é—® Windows æ–‡ä»¶ç³»ç»Ÿ
4. âœ… æ€§èƒ½æ¥è¿‘åŸç”Ÿ Linux
5. âœ… ä¾¿äºå¼€å‘å’Œè°ƒè¯•

## ğŸš€ å¿«é€Ÿå¼€å§‹ (WSL2)

```powershell
# 1. å®‰è£… WSL2
wsl --install

# 2. é‡å¯ç”µè„‘

# 3. æ‰“å¼€ Ubuntu ç»ˆç«¯ï¼Œè¿è¡Œå®‰è£…è„šæœ¬
# (æˆ‘å¯ä»¥ä¸ºä½ ç”Ÿæˆä¸€ä¸ªè‡ªåŠ¨åŒ–å®‰è£…è„šæœ¬)
```

éœ€è¦æˆ‘å¸®ä½ ï¼š
1. ç”Ÿæˆ WSL2 è‡ªåŠ¨åŒ–å®‰è£…è„šæœ¬ï¼Ÿ
2. é…ç½® Docker æ–¹æ¡ˆï¼Ÿ
3. è¿˜æ˜¯ç»§ç»­å°è¯•åŸç”Ÿ Windows å®‰è£…ï¼Ÿ

è¯·å‘Šè¯‰æˆ‘ä½ çš„é€‰æ‹©ï¼Œæˆ‘ä¼šæä¾›è¯¦ç»†çš„æ­¥éª¤æŒ‡å¯¼ï¼
